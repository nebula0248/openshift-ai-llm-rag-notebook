{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "91e41b41-f60a-4b0f-91a1-cd273b60f21b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.2.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install -q einops==0.7.0 langchain==0.1.9 pypdf==4.0.2 pymilvus==2.3.6 sentence-transformers==2.4.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "25ee4f68-db74-4fd7-b94b-9d31ffd09c8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import os\n",
    "from langchain.document_loaders import PyPDFDirectoryLoader, WebBaseLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.embeddings.huggingface import HuggingFaceEmbeddings\n",
    "from langchain_community.vectorstores import Milvus\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cc1f1f10-afc4-4162-9b26-2f771730bbbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_and_load_documentation_pdfs(product_name, product_version, sections, language):\n",
    "    pdfs = [f\"https://docs.redhat.com/{language}/documentation/{product_name}/{product_version}/pdf/{section}/{product_name}-{product_version}-{section}-{language}.pdf\" for section in sections]\n",
    "    pdfs_to_urls = {f\"{product_name}-{product_version}-{section}-{language}\": f\"https://docs.redhat.com/{language}/documentation/{product_name}/{product_version}/html-single/{section}/index\" for section in sections}\n",
    "\n",
    "    docs_dir = f\"{product_name}-{product_version}-{language}\"\n",
    "    pdf_folder_path = f\"./{product_name}-{product_version}-{language}\"\n",
    "\n",
    "    if not os.path.exists(docs_dir):\n",
    "        os.mkdir(docs_dir)\n",
    "\n",
    "    for pdf in pdfs:\n",
    "        try:\n",
    "            response = requests.get(pdf)\n",
    "        except:\n",
    "            print(f\"Skipped {pdf}\")\n",
    "            continue\n",
    "        if response.status_code != 200:\n",
    "            print(f\"Skipped {pdf}\")\n",
    "            continue\n",
    "        with open(f\"{docs_dir}/{pdf.split('/')[-1]}\", 'wb') as f:\n",
    "            f.write(response.content)\n",
    "\n",
    "    pdf_loader = PyPDFDirectoryLoader(pdf_folder_path)\n",
    "    pdf_docs = pdf_loader.load()\n",
    "\n",
    "    # Inject document metadata so that we can find out the LLM answers' source later\n",
    "    for doc in pdf_docs:\n",
    "        doc.metadata[\"source\"] = pdfs_to_urls[Path(doc.metadata[\"source\"]).stem.lower()]\n",
    "\n",
    "    return pdf_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "201543b5-59a3-4d21-af92-04269b524c5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_and_load_website_text_contents(websites):\n",
    "    website_loader = WebBaseLoader(websites)\n",
    "    website_docs = website_loader.load()\n",
    "\n",
    "    return website_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d7830284-8c3b-4538-bf5d-0023e455f083",
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_and_text_splitting(pdf_docs, website_docs):\n",
    "    merged_documents = pdf_docs + website_docs\n",
    "\n",
    "    text_splitter = RecursiveCharacterTextSplitter(chunk_size=1024,\n",
    "                                                   chunk_overlap=128)\n",
    "    all_splits = text_splitter.split_documents(merged_documents)\n",
    "    return all_splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "555a2ee8-d870-46ac-93db-3eb3da303c39",
   "metadata": {},
   "outputs": [],
   "source": [
    "def inject_into_vector_db(document_splits, embedding_model_name, vector_db_collection_name):\n",
    "    # Create embedding\n",
    "    model_kwargs = {\n",
    "        'device': 'cuda',\n",
    "        'trust_remote_code': True,\n",
    "    }\n",
    "    encode_kwargs = {\n",
    "        'normalize_embeddings': False\n",
    "    }\n",
    "    embeddings = HuggingFaceEmbeddings(\n",
    "        model_name=embedding_model_name,\n",
    "        model_kwargs=model_kwargs,\n",
    "        encode_kwargs=encode_kwargs,\n",
    "        show_progress=True\n",
    "    )\n",
    "\n",
    "    # Connect to vector DB\n",
    "    db = Milvus(\n",
    "        embedding_function=embeddings,\n",
    "        connection_args={\"host\": MILVUS_HOST, \"port\": MILVUS_PORT, \"user\": MILVUS_USERNAME, \"password\": MILVUS_PASSWORD},\n",
    "        collection_name=vector_db_collection_name,\n",
    "        metadata_field=\"metadata\",\n",
    "        text_field=\"page_content\",\n",
    "        auto_id=True,\n",
    "        drop_old=True\n",
    "    )\n",
    "\n",
    "    # Insert into vector DB\n",
    "    db.add_documents(document_splits)\n",
    "\n",
    "    return db"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f28aad27-191f-487b-8e31-6f83f2a2b867",
   "metadata": {},
   "source": [
    "# Program starts here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "600cd763-6ecc-4c77-89c0-47108c31c44e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "MILVUS_HOST = \"vectordb-milvus.milvus.svc.cluster.local\"\n",
    "MILVUS_PORT = 19530\n",
    "MILVUS_USERNAME = os.getenv('MILVUS_USERNAME')\n",
    "MILVUS_PASSWORD = os.getenv('MILVUS_PASSWORD')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01969a04-fe2b-419c-bf48-53557c6ad278",
   "metadata": {},
   "source": [
    "### Download Red Hat product documentation PDFs first"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1869b30b-d6fd-4ca0-a2ac-7c334aadd0eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/app-root/lib64/python3.11/site-packages/pypdf/_crypt_providers/_cryptography.py:32: CryptographyDeprecationWarning: ARC4 has been moved to cryptography.hazmat.decrepit.ciphers.algorithms.ARC4 and will be removed from this module in 48.0.0.\n",
      "  from cryptography.hazmat.primitives.ciphers.algorithms import AES, ARC4\n"
     ]
    }
   ],
   "source": [
    "pdf_documents = download_and_load_documentation_pdfs(\n",
    "    product_name=\"red_hat_openshift_ai_self-managed\",\n",
    "    product_version=\"2.16\",\n",
    "    sections=[\n",
    "        \"release_notes\",\n",
    "        \"introduction_to_red_hat_openshift_ai\",\n",
    "        \"getting_started_with_red_hat_openshift_ai_self-managed\",\n",
    "        \"openshift_ai_tutorial_-_fraud_detection_example\",\n",
    "        \"working_on_data_science_projects\",\n",
    "        \"serving_models\",\n",
    "        \"monitoring_data_science_models\",\n",
    "        \"managing_resources\",\n",
    "        \"installing_and_uninstalling_openshift_ai_self-managed\",\n",
    "        \"installing_and_uninstalling_openshift_ai_self-managed_in_a_disconnected_environment\",\n",
    "        \"upgrading_openshift_ai_self-managed\",\n",
    "        \"upgrading_openshift_ai_self-managed_in_a_disconnected_environment\",\n",
    "    ],\n",
    "    language=\"en\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f5fb6d2-347b-4771-bb9d-cd88bea446ac",
   "metadata": {},
   "source": [
    "### Also save websites relevant to Red Hat products"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "efc64e9b-daf2-48df-9070-378d784efc07",
   "metadata": {},
   "outputs": [],
   "source": [
    "website_documents = download_and_load_website_text_contents(\n",
    "    websites=[\n",
    "        \"https://ai-on-openshift.io/getting-started/openshift/\",\n",
    "        \"https://ai-on-openshift.io/getting-started/opendatahub/\",\n",
    "        \"https://ai-on-openshift.io/getting-started/openshift-ai/\",\n",
    "        \"https://ai-on-openshift.io/odh-rhoai/configuration/\",\n",
    "        \"https://ai-on-openshift.io/odh-rhoai/custom-notebooks/\",\n",
    "        \"https://ai-on-openshift.io/odh-rhoai/nvidia-gpus/\",\n",
    "        \"https://ai-on-openshift.io/odh-rhoai/custom-runtime-triton/\",\n",
    "        \"https://ai-on-openshift.io/odh-rhoai/openshift-group-management/\",\n",
    "        \"https://ai-on-openshift.io/tools-and-applications/minio/minio/\",\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c325b3c-80e2-4dbd-9b8c-9db83888b230",
   "metadata": {},
   "source": [
    "### Combine both and split them into chunks that can save into Vector DB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9b67ac7f-c591-432d-835d-cb69d959ae9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "split_documents = combine_and_text_splitting(pdf_documents, website_documents)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5661477-e14e-41b2-bea4-02c4fc159f28",
   "metadata": {},
   "source": [
    "### Inject all split document into Vector DB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "edba4a08-2194-4df1-9091-6f2b596757a1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1a80d524b1784c3190998d0d5b904816",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/39 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "vector_db = inject_into_vector_db(\n",
    "    document_splits=split_documents,\n",
    "    embedding_model_name=\"ibm-granite/granite-embedding-278m-multilingual\",\n",
    "    vector_db_collection_name=\"openshift_ai_2_16_en_document\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f54d627d-a8bf-4c64-9a46-c69b9d13387a",
   "metadata": {},
   "source": [
    "### Verify if documents are injected into Vector DB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "489c6e6d-c42c-4de4-87cf-8edfd0e63da3",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e05d88af29fc4a49a8068cd63feae8ac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------\n",
      "Score:  0.3126489222049713\n",
      "But don't worry, OpenShift AI and Open Data Hub take care of this part for you when you launch notebooks, workbenches, model servers, or pipeline runtimes!\n",
      "Installation\n",
      "Here is the documentation you can follow:\n",
      "\n",
      "OpenShift AI documentation\n",
      "NVIDIA documentation (more detailed)\n",
      "\n",
      "Advanced configuration\n",
      "Working with taints\n",
      "In many cases, you will want to restrict access to GPUs, or be able to provide choice between different types of GPUs: simply stating \"I want a GPU\" is not enough. Also, if you want to make sure that only the Pods requiring GPUs end up on GPU-enabled nodes (and not other Pods that just end up being there at random because that's how Kubernetes works...), you're at the right place!\n",
      "The only supported method at the moment to achieve this is to taint nodes, then apply tolerations on the Pods depending on where you want them scheduled. If you don't pay close attention though when applying taints on Nodes, you may end up with the NVIDIA drivers not installed on those nodes...\n",
      "In this case you must:\n",
      "--------------------------------------------------------------------------------\n",
      "--------------------------------------------------------------------------------\n",
      "Score:  0.3817702531814575\n",
      "Using NVIDIA GPUs on OpenShift\n",
      "    \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "      How does this work?\n",
      "    \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "      Installation\n",
      "    \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "      Advanced configuration\n",
      "    \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "      Working with taints\n",
      "    \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "      Autoscaler and GPUs\n",
      "    \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "      Configuration\n",
      "    \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "      Scaling to zero\n",
      "    \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "      GPU Partitioning / Sharing\n",
      "    \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "      Time Slicing (GPU sharing)\n",
      "    \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "      Configuration\n",
      "    \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "      Multi-Instance GPU (MIG)\n",
      "    \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "      Multi-Process Service (MPS)\n",
      "    \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "      Aggregating GPUs (Multi-GPU)\n",
      "--------------------------------------------------------------------------------\n",
      "--------------------------------------------------------------------------------\n",
      "Score:  0.3890341520309448\n",
      "NVIDIA GPUs - AI on OpenShift\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "          Skip to content\n",
      "        \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "            AI on OpenShift\n",
      "          \n",
      "\n",
      "\n",
      "\n",
      "            \n",
      "              NVIDIA GPUs\n",
      "            \n",
      "          \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "            Initializing search\n",
      "          \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "    GitHub\n",
      "  \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "        \n",
      "  \n",
      "    \n",
      "  \n",
      "  Home\n",
      "\n",
      "      \n",
      "\n",
      "\n",
      "\n",
      "          \n",
      "  \n",
      "    \n",
      "  \n",
      "  Overview\n",
      "\n",
      "        \n",
      "\n",
      "\n",
      "\n",
      "          \n",
      "  \n",
      "    \n",
      "  \n",
      "  ODH/RHOAI How-Tos\n",
      "\n",
      "        \n",
      "\n",
      "\n",
      "\n",
      "          \n",
      "  \n",
      "    \n",
      "  \n",
      "  Applications and Patterns\n",
      "\n",
      "        \n",
      "\n",
      "\n",
      "\n",
      "          \n",
      "  \n",
      "    \n",
      "  \n",
      "  Predictive AI\n",
      "\n",
      "        \n",
      "\n",
      "\n",
      "\n",
      "          \n",
      "  \n",
      "    \n",
      "  \n",
      "  Generative AI\n",
      "\n",
      "        \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "    AI on OpenShift\n",
      "  \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "    GitHub\n",
      "  \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "    Home\n",
      "  \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "    Overview\n",
      "  \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "            Overview\n",
      "          \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "    What's new?\n",
      "  \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "            What's new?\n",
      "          \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "    Latest updates\n",
      "  \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "    Getting Started\n",
      "  \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "            Getting Started\n",
      "          \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "    Why this site?\n",
      "  \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "    OpenShift and AI\n",
      "  \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "    Open Data Hub\n",
      "--------------------------------------------------------------------------------\n",
      "--------------------------------------------------------------------------------\n",
      "Score:  0.3926379978656769\n",
      "Getting Started\n",
      "          \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "    Why this site?\n",
      "  \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "    OpenShift and AI\n",
      "  \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "    Open Data Hub\n",
      "  \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "    OpenShift AI\n",
      "  \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "    ODH/RHOAI How-Tos\n",
      "  \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "            ODH/RHOAI How-Tos\n",
      "          \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "    From Zero to Workbench\n",
      "  \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "            From Zero to Workbench\n",
      "          \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "    Using the CLI\n",
      "  \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "    Using the UI\n",
      "  \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "    Using Developer Hub\n",
      "  \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "    Advanced Configuration\n",
      "  \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "            Advanced Configuration\n",
      "          \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "    Accelerator Profiles\n",
      "  \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "    Custom notebooks\n",
      "  \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "    Custom Serving Runtime (Triton)\n",
      "  \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "    Dashboard configuration\n",
      "  \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "    GitOps (CRs, objects,...)\n",
      "  \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "    Kueue preemption\n",
      "  \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "    Model serving type modification\n",
      "  \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "    NVIDIA GPUs\n",
      "  \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "    NVIDIA GPUs\n",
      "  \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "      Table of contents\n",
      "    \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "      Using NVIDIA GPUs on OpenShift\n",
      "    \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "      How does this work?\n",
      "    \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "      Installation\n",
      "    \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "      Advanced configuration\n",
      "    \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "      Working with taints\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "query = \"How can I work with GPU and taints in OpenShift AI?\"\n",
    "docs_with_score = vector_db.similarity_search_with_score(query)\n",
    "\n",
    "for doc, score in docs_with_score:\n",
    "    print(\"-\" * 80)\n",
    "    print(\"Score: \", score)\n",
    "    print(doc.page_content)\n",
    "    print(\"-\" * 80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af15b379-8448-4e83-bbd3-39bc5ec8a0f5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
